{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059db958",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc88cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import shap\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a96b38",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6febe0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time         A         B         C         D         E         F         G  \\\n",
      "0     0  0.207366 -0.159951 -0.634176 -0.580962 -0.266505  0.060173 -0.475257   \n",
      "1     1  0.188828 -0.265508  0.042143 -0.550442 -0.132319 -0.185219  0.028295   \n",
      "2     2 -0.144261 -0.577142 -0.214634 -0.747391 -0.184255 -0.464831 -0.085181   \n",
      "3     3  0.208982 -0.310449  0.513708 -0.562868  0.742308 -0.305487  0.762246   \n",
      "4     4  0.093320 -0.358156  0.173188 -0.687296 -0.161461 -0.116062 -0.245748   \n",
      "\n",
      "          H         I         J         K         L         M         N  \\\n",
      "0 -1.486516 -0.332594 -0.671466 -0.226149 -0.187624 -0.780237 -0.785965   \n",
      "1  0.093210 -0.518139 -0.251917 -0.347845 -0.359069 -0.161254  0.020401   \n",
      "2  0.700449 -0.603438  0.197773 -0.566696 -0.580799  0.202726  0.135261   \n",
      "3  1.363020 -0.384575  0.525556 -0.348514 -0.428099  0.548993  0.471031   \n",
      "4  0.863372 -0.655588 -0.263358 -0.557428 -0.481214  0.083602  0.003087   \n",
      "\n",
      "         Y1        Y2  \n",
      "0 -0.935902 -0.310081  \n",
      "1 -0.089707 -0.305374  \n",
      "2 -0.077855 -0.631485  \n",
      "3  0.941271 -0.535212  \n",
      "4 -0.039582 -0.490561  \n",
      "   id   time         A         B         C         D         E         F  \\\n",
      "0   1  80005 -0.371888 -0.273485  0.538326 -0.377691  1.283159 -0.286957   \n",
      "1   2  80006 -0.459598 -0.514915 -0.235153 -0.262379  0.044343 -0.429888   \n",
      "2   3  80007 -0.381609 -0.265023 -0.629131 -0.186288 -0.146302 -0.357875   \n",
      "3   4  80008 -0.371423 -0.106279 -1.142702 -0.200429 -0.176918 -0.354048   \n",
      "4   5  80009 -0.309393 -0.015144 -1.099371 -0.405841 -0.239068 -0.403306   \n",
      "\n",
      "          G         H         I         J         K         L         M  \\\n",
      "0  0.439415  0.020831 -0.295480  0.117643 -0.369900 -0.378902  0.470166   \n",
      "1 -0.059034 -0.725713 -0.407681 -0.255702 -0.461901 -0.249516 -0.216745   \n",
      "2  0.114223 -0.359341 -0.190712 -0.404083 -0.272153 -0.193158 -0.679351   \n",
      "3 -0.230199 -0.305226  0.185342 -0.333010  0.518678 -0.028775 -0.610620   \n",
      "4 -0.983134 -1.067315 -0.105132 -0.809948  0.185197 -0.150254 -1.080190   \n",
      "\n",
      "          N  \n",
      "0  0.411796  \n",
      "1 -0.328599  \n",
      "2 -0.476331  \n",
      "3 -0.846772  \n",
      "4 -0.685936  \n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n",
    "\n",
    "FEATURES = [col for col in train_data.columns if col in list(\"ABCDEFGHIJKLMN\")]\n",
    "TARGET = [\"Y1\", \"Y2\"]\n",
    "\n",
    "train_data= train_data.sort_values(\"time\")\n",
    "test_data= test_data.sort_values(\"time\")\n",
    "\n",
    "strong_features = ['C','E', 'G', 'H','J', 'M', 'N']\n",
    "\n",
    "for col in strong_features:\n",
    "    train_data[f\"{col}_roll_mean_5\"] = train_data[col].rolling(2, min_periods=1).mean()\n",
    "    train_data[f\"{col}_roll_std_5\"] = train_data[col].rolling(2, min_periods=1).std()\n",
    "    train_data[f\"{col}_roll_diff1\"] = train_data[col].diff(1)\n",
    "\n",
    "    test_data[f\"{col}_roll_mean_5\"] = test_data[col].rolling(2, min_periods=1).mean()\n",
    "    test_data[f\"{col}_roll_std_5\"] = test_data[col].rolling(2, min_periods=1).std()\n",
    "    test_data[f\"{col}_roll_diff1\"] = test_data[col].diff(1)\n",
    "\n",
    "\n",
    "NEW_FEATURES = [col for col in train_data.columns if \"roll\" in col or \"diff\" in col]\n",
    "FEATURES_EXTENDED = FEATURES + NEW_FEATURES\n",
    "\n",
    "X = train_data[FEATURES_EXTENDED].copy()\n",
    "y1 = train_data[\"Y1\"].copy()\n",
    "y2 = train_data[\"Y2\"].copy()\n",
    "y1y2 = train_data[[\"Y1\", \"Y2\"]].copy()\n",
    "X_test = test_data[FEATURES_EXTENDED].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e0ecdc",
   "metadata": {},
   "source": [
    "**Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd39606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make XGBRegressor model\n",
    "def make_xgbregressor():\n",
    "    return XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1,\n",
    "        reg_alpha=0,\n",
    "        objective='reg:squarederror',\n",
    "        tree_method='hist',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=1,\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "#Test without early stopping, and with RandomSearchCV for hyperparameter tuning\n",
    "def make_xgbregressor_no_early_stopping():\n",
    "    return XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        objective='reg:squarederror',\n",
    "        tree_method='hist',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='rmse'\n",
    "    )\n",
    "\n",
    "#Parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_child_weight\": [1, 2, 5, 8],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"reg_lambda\": [0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "    \"reg_alpha\": [0.0, 0.1, 0.5, 1.0],\n",
    "    \"gamma\": [0, 0.1, 0.3, 0.5, 1.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88befd97",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be7cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, X_test, cv, make_model_fn):\n",
    "    oof = np.zeros(len(X))\n",
    "    test_fold_preds = []\n",
    "\n",
    "    for fold, (train, val) in enumerate(cv.split(X)):\n",
    "        X_train, X_val = X.iloc[train], X.iloc[val]\n",
    "        y_train, y_val = y.iloc[train], y.iloc[val]\n",
    "\n",
    "        model=make_model_fn()\n",
    "\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        oof[val] = model.predict(X_val)\n",
    "\n",
    "        test_fold_preds.append(model.predict(X_test))\n",
    "\n",
    "        print(f\"fold {fold+1} R^2: {r2_score(y_val, oof[val]):.4f}\")\n",
    "        cv_r2 = r2_score(y, oof)\n",
    "        print(f\"CV R^2: {cv_r2:.4f}\")\n",
    "        print()\n",
    "\n",
    "        test_pred = np.mean(test_fold_preds, axis=0)\n",
    "\n",
    "    return oof, test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e188c",
   "metadata": {},
   "source": [
    "**Defining Folds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bdfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time series cross validation\n",
    "tscv = TimeSeriesSplit(n_splits=5) \n",
    "\n",
    "#Kfold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97e44a",
   "metadata": {},
   "source": [
    "**Running the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec6f46b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Y1\n",
      "fold 1 R^2: 0.7374\n",
      "CV R^2: 0.0529\n",
      "\n",
      "fold 2 R^2: 0.6935\n",
      "CV R^2: 0.1317\n",
      "\n",
      "fold 3 R^2: 0.7594\n",
      "CV R^2: 0.2809\n",
      "\n",
      "fold 4 R^2: 0.7673\n",
      "CV R^2: 0.4266\n",
      "\n",
      "fold 5 R^2: 0.7138\n",
      "CV R^2: 0.6373\n",
      "\n",
      "\n",
      "Training for Y2\n",
      "fold 1 R^2: 0.6896\n",
      "CV R^2: 0.0747\n",
      "\n",
      "fold 2 R^2: 0.6445\n",
      "CV R^2: 0.1371\n",
      "\n",
      "fold 3 R^2: 0.6977\n",
      "CV R^2: 0.2345\n",
      "\n",
      "fold 4 R^2: 0.6976\n",
      "CV R^2: 0.3285\n",
      "\n",
      "fold 5 R^2: 0.5449\n",
      "CV R^2: 0.5135\n",
      "\n",
      "Hyperparameter tuning for Y1\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters for Y1: {'subsample': 1.0, 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'min_child_weight': 8, 'max_depth': 5, 'learning_rate': 0.03, 'gamma': 0.5, 'colsample_bytree': 0.6}\n",
      "Best CV R^2 for Y1: 0.7347\n",
      "\n",
      "Hyperparameter tuning for Y2\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters for Y2: {'subsample': 0.6, 'reg_lambda': 10.0, 'reg_alpha': 1.0, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.01, 'gamma': 1.0, 'colsample_bytree': 1.0}\n",
      "Best CV R^2 for Y2: 0.6462\n"
     ]
    }
   ],
   "source": [
    "#No parameter tuning\n",
    "print(\"Training for Y1\")\n",
    "oof_y1, test_pred_y1 = train_model(X, y1, X_test, tscv, make_xgbregressor)\n",
    "print(\"\\nTraining for Y2\")\n",
    "oof_y2, test_pred_y2 = train_model(X, y2, X_test, tscv, make_xgbregressor)\n",
    "\n",
    "#RandomizedSearchCV for hyperparameter tuning (without early stopping)\n",
    "print(\"Hyperparameter tuning for Y1\")\n",
    "rs_y1 = RandomizedSearchCV(\n",
    "    estimator=make_xgbregressor_no_early_stopping(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='r2',\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rs_y1.fit(X, y1)\n",
    "print(f\"Best parameters for Y1: {rs_y1.best_params_}\")\n",
    "print(f\"Best CV R^2 for Y1: {rs_y1.best_score_:.4f}\")\n",
    "best_y1 = rs_y1.best_estimator_\n",
    "test_pred_y1_tuned = best_y1.predict(X_test)\n",
    "\n",
    "print(\"\\nHyperparameter tuning for Y2\")\n",
    "rs_y2 = RandomizedSearchCV(\n",
    "    estimator=make_xgbregressor_no_early_stopping(),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='r2',\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "rs_y2.fit(X, y2)\n",
    "print(f\"Best parameters for Y2: {rs_y2.best_params_}\")\n",
    "print(f\"Best CV R^2 for Y2: {rs_y2.best_score_:.4f}\")\n",
    "best_y2 = rs_y2.best_estimator_\n",
    "test_pred_y2_tuned = best_y2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f53b85",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58b7e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv\n",
      "   id        Y1        Y2\n",
      "0   1  0.287263 -0.528851\n",
      "1   2 -0.184273 -0.523373\n",
      "2   3 -0.208544 -0.349863\n",
      "3   4 -0.355431 -0.204670\n",
      "4   5 -0.917815 -0.028433\n"
     ]
    }
   ],
   "source": [
    "#Prepare submission\n",
    "submission = test_data[[\"id\"]].copy()\n",
    "submission[\"Y1\"] = test_pred_y1_tuned\n",
    "submission[\"Y2\"] = test_pred_y2_tuned\n",
    "\n",
    "\n",
    "assert submission.isnull().sum().sum() == 0, \"There are missing values in submission!\"\n",
    "\n",
    "# save to CSV\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Saved submission.csv\")\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
